{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaugg9BOd1EauQmqFd4pQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoodMoodMan/Stock_ML/blob/main/Stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSaQERgASixM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Created on Sat Aug 19 05:09:59 2023\n",
        "\n",
        "@author: Noam\n",
        "\"\"\"\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import urllib\n",
        "import datetime as dt\n",
        "import json\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General fit function for various models we will use\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history\n"
      ],
      "metadata": {
        "id": "a2YQG3RKTFJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA WINDOWING GENERATOR\n",
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df, val_df, test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def split_window(self, features):\n",
        "      inputs = features[:, self.input_slice, :]\n",
        "      labels = features[:, self.labels_slice, :]\n",
        "      if self.label_columns is not None:\n",
        "          labels = tf.stack(\n",
        "              [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "              axis=-1)\n",
        "\n",
        "      # Slicing doesn't preserve static shape information, so set the shapes\n",
        "      # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "      inputs.set_shape([None, self.input_width, None])\n",
        "      labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "      return inputs, labels\n",
        "\n",
        "  def plot(self, plot_col, max_subplots=3,model=None):\n",
        "      inputs, labels = self.example\n",
        "      plt.figure(figsize=(12, 8))\n",
        "      plot_col_index = self.column_indices[plot_col]\n",
        "      max_n = min(max_subplots, len(inputs))\n",
        "      for n in range(max_n):\n",
        "        plt.subplot(max_n, 1, n+1)\n",
        "        plt.ylabel(f'{plot_col} [normed]')\n",
        "        plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "                 label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "        if self.label_columns:\n",
        "          label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "        else:\n",
        "          label_col_index = plot_col_index\n",
        "\n",
        "        if label_col_index is None:\n",
        "          continue\n",
        "\n",
        "        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "        if model is not None:\n",
        "          predictions = model(inputs)\n",
        "          plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                      marker='X', edgecolors='k', label='Predictions',\n",
        "                      c='#ff7f0e', s=64)\n",
        "\n",
        "        if n == 0:\n",
        "          plt.legend()\n",
        "\n",
        "      plt.xlabel('Time [d]')\n",
        "\n",
        "  def make_dataset(self, data):\n",
        "      data = np.array(data, dtype=np.float32)\n",
        "      ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "          data=data,\n",
        "          targets=None,\n",
        "          sequence_length=self.total_window_size,\n",
        "          sequence_stride=1,\n",
        "          shuffle=True,\n",
        "          batch_size=32,)\n",
        "\n",
        "      ds = ds.map(self.split_window)\n",
        "\n",
        "      return ds\n",
        "\n",
        "  @property\n",
        "  def train(self):\n",
        "    return self.make_dataset(self.train_df)\n",
        "\n",
        "  @property\n",
        "  def val(self):\n",
        "    return self.make_dataset(self.val_df)\n",
        "\n",
        "  @property\n",
        "  def test(self):\n",
        "    return self.make_dataset(self.test_df)\n",
        "\n",
        "  @property\n",
        "  def example(self):\n",
        "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "    result = getattr(self, '_example', None)\n",
        "    if result is None:\n",
        "      # No example batch was found, so get one from the `.train` dataset\n",
        "      result = next(iter(self.train))\n",
        "      # And cache it for next time\n",
        "      self._example = result\n",
        "    return result\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])\n",
        "\n"
      ],
      "metadata": {
        "id": "_VQIdE9lSy6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline prediction model, returns last sample value as next 'prediction' (reasonable accuracy as stock prices change slowly)\n",
        "class Baseline(tf.keras.Model):\n",
        "  def __init__(self, label_index=None):\n",
        "    super().__init__()\n",
        "    self.label_index = label_index\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.label_index is None:\n",
        "      return inputs\n",
        "    result = inputs[:, :, self.label_index]\n",
        "    return result[:, :, tf.newaxis]\n",
        "\n",
        "class ResidualWrapper(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    delta = self.model(inputs, *args, **kwargs)\n",
        "\n",
        "    # The prediction for each time step is the input\n",
        "    # from the previous time step plus the delta\n",
        "    # calculated by the model.\n",
        "    return inputs + delta\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o2uvZH1-Sy9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple wrapper for Residual Models tracking the Delta and Previous Output\n",
        "class ResidualWrapper(tf.keras.Model):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    delta = self.model(inputs, *args, **kwargs)\n",
        "\n",
        "    # The prediction for each time step is the input\n",
        "    # from the previous time step plus the delta\n",
        "    # calculated by the model.\n",
        "    return inputs + delta\n",
        "\n",
        "class MultiStepLastBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n",
        "\n",
        "class RepeatBaseline(tf.keras.Model):\n",
        "  def call(self, inputs):\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "3rDTnLZaW8f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INITIAL SETTINGS\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "\n",
        "api_key = 'M8UQX1OZQCMXC7R5'\n",
        "\n",
        "# Selected Stock Ticker\n",
        "stock_selected = \"NVDA\"\n",
        "\n",
        "# url request string for selected ticker\n",
        "# JSON file with stock market data for stock_selected\n",
        "url_string = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=%s&outputsize=full&apikey=%s\"%(stock_selected,api_key)\n",
        "\n",
        "# Save data\n",
        "file_to_save = 'stock_data-%s.csv'%stock_selected\n",
        "\n",
        "# EPOCHS\n",
        "MAX_EPOCHS = 20\n",
        "\n",
        "# performance info\n",
        "val_performance = {}\n",
        "performance = {}\n",
        "multi_val_performance = {}\n",
        "multi_performance = {}\n",
        "\n"
      ],
      "metadata": {
        "id": "tQClbx14SzAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP\n",
        "\n",
        "# If data is not already saved\n",
        "if not os.path.exists(file_to_save):\n",
        "    # load json from url request\n",
        "    # store date, low, high, volume, close, open values to a Pandas DataFrame\n",
        "    with urllib.request.urlopen(url_string) as url:\n",
        "        data = json.loads(url.read().decode())\n",
        "        # extract actual data from json\n",
        "        data = data['Time Series (Daily)']\n",
        "        df = pd.DataFrame(columns=['Date','Low','High','Close','Open'])\n",
        "        for k,v in data.items():\n",
        "            date = dt.datetime.strptime(k, '%Y-%m-%d')\n",
        "            data_row = [date.date(),float(v['3. low']),float(v['2. high']),\n",
        "                        float(v['4. close']),float(v['1. open'])]\n",
        "            df.loc[-1,:] = data_row\n",
        "            df.index = df.index + 1\n",
        "    print('Data saved to : %s'%file_to_save)\n",
        "    df.to_csv(file_to_save)\n",
        "\n",
        "# If data is saved, only load\n",
        "else:\n",
        "    print('File already exists. Loading data from CSV')\n",
        "    df = pd.read_csv(file_to_save)\n",
        "\n",
        "df = df.sort_values('Date')\n",
        "\n",
        "\n",
        "# fix date strings to numeric features\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Day'] = df['Date'].dt.day\n",
        "\n",
        "df.drop(columns=['Date'], inplace=True)\n"
      ],
      "metadata": {
        "id": "mqyEzzwwSzCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA SETS SPLIT\n",
        "\n",
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]\n",
        "\n",
        "num_features = df.shape[1]\n",
        "\n",
        "# Calculate mean and standard deviation\n",
        "train_mean = train_df.mean(numeric_only=True)\n",
        "train_std = train_df.std(numeric_only=True)\n",
        "\n",
        "# normalize data sets around [0,1]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))  # Scale features between 0 and 1\n",
        "# based on training data set ONLY\n",
        "scaler.fit(train_df)\n",
        "train_df = scaler.transform(train_df)\n",
        "val_df = scaler.transform(val_df)\n",
        "test_df = scaler.transform(test_df)\n",
        "\n",
        "# convert the NumPy arrays back to DataFrames\n",
        "train_df = pd.DataFrame(train_df, columns=df.columns)\n",
        "val_df = pd.DataFrame(val_df, columns=df.columns)\n",
        "test_df = pd.DataFrame(test_df, columns=df.columns)\n",
        "\n",
        "# generate data window, 24 samples (days) with 24 (days) offset, target label is closing price\n",
        "w1 = WindowGenerator(input_width=24, label_width=1, shift=24, train_df = train_df, val_df = val_df, test_df = test_df,\n",
        "                     label_columns=['Close'])\n",
        "\n",
        "# generate data window, 7 samples (days) with 1 (days) offset, target label is closing price\n",
        "w2 = WindowGenerator(input_width=7, label_width=1, shift=1, train_df = train_df, val_df = val_df, test_df = test_df,\n",
        "                     label_columns=['Close'])\n",
        "\n",
        "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
        "                           np.array(train_df[100:100+w2.total_window_size]),\n",
        "                           np.array(train_df[200:200+w2.total_window_size])])\n",
        "\n",
        "example_inputs, example_labels = w2.split_window(example_window)\n",
        "\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print(f'Window shape: {example_window.shape}')\n",
        "print(f'Inputs shape: {example_inputs.shape}')\n",
        "print(f'Labels shape: {example_labels.shape}')\n",
        "\n",
        "w2.plot(plot_col='Close')\n",
        "\n",
        "for example_inputs, example_labels in w2.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
        "\n",
        "\n",
        "single_step_window = WindowGenerator(train_df = train_df, val_df = val_df, test_df = test_df,\n",
        "    input_width=1, label_width=1, shift=1,\n",
        "    label_columns=['Close'])\n",
        "\n",
        "for example_inputs, example_labels in single_step_window.train.take(1):\n",
        "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "  print(f'Labels shape (batch, time, features): {example_labels.shape}')\n"
      ],
      "metadata": {
        "id": "TmnWHw1_SzFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate baseline model for single step window, LOSS = MSE\n",
        "baseline = Baseline(label_index=column_indices['Close'])\n",
        "\n",
        "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
        "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)\n",
        "\n",
        "# this wide window predicts one step (day) at a time, but checks a month of predictions (input is 30 days, target labels are 30 days)\n",
        "\n",
        "wide_window = WindowGenerator(train_df = train_df, val_df = val_df, test_df = test_df,\n",
        "    input_width=30, label_width=30, shift=1,\n",
        "    label_columns=['Close'])\n",
        "\n",
        "\n",
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', baseline(wide_window.example[0]).shape)\n",
        "\n",
        "wide_window.plot(model=baseline,plot_col = 'Close')"
      ],
      "metadata": {
        "id": "C8j-74CzSzHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear model on single step window\n",
        "linear = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "history = compile_and_fit(linear, single_step_window)\n",
        "\n",
        "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
        "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)\n",
        "\n",
        "# plot on wide window (the fitting from the single step window works for this window as well, as they evaulate the same way)\n",
        "wide_window.plot('Close',model=linear)"
      ],
      "metadata": {
        "id": "Pob6W2_hSzKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dense model that consists of 3 dense layers with relu activation function, a deeper and more powerful model than the linear one\n",
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "history = compile_and_fit(dense, single_step_window)\n",
        "\n",
        "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
        "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)\n",
        "\n",
        "\n",
        "wide_window.plot('Close',model=dense)"
      ],
      "metadata": {
        "id": "VEMU4mS1SyfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS MODEL WORKS ON PRESET WINDOW INPUT WIDTH ONLY\n",
        "# set to 3\n",
        "CONV_WIDTH = 3\n",
        "conv_window = WindowGenerator(\n",
        "    train_df = train_df, val_df = val_df, test_df = test_df,\n",
        "    input_width=CONV_WIDTH,\n",
        "    label_width=1,\n",
        "    shift=1,\n",
        "    label_columns=['Close'])\n",
        "\n",
        "multi_step_dense = tf.keras.Sequential([\n",
        "    # Shape: (time, features) => (time*features)\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "    # Add back the time dimension.\n",
        "    # Shape: (outputs) => (1, outputs)\n",
        "    tf.keras.layers.Reshape([1, -1]),\n",
        "])\n",
        "\n",
        "print('Input shape:', wide_window.example[0].shape)\n",
        "\n",
        "history = compile_and_fit(multi_step_dense, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.val)\n",
        "performance['Multi step dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)\n",
        "conv_window.plot('Close',model = multi_step_dense)\n"
      ],
      "metadata": {
        "id": "a9gudqAITkaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAME MODEL USING CONVOLUTION LAYER\n",
        "# works with all window shapes (different input width)\n",
        "conv_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32,\n",
        "                           kernel_size=(CONV_WIDTH,),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])\n",
        "\n",
        "print(\"Conv model on `conv_window`\")\n",
        "print('Input shape:', conv_window.example[0].shape)\n",
        "print('Output shape:', conv_model(conv_window.example[0]).shape)\n",
        "\n",
        "history = compile_and_fit(conv_model, conv_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Conv'] = conv_model.evaluate(conv_window.val)\n",
        "performance['Conv'] = conv_model.evaluate(conv_window.test, verbose=0)\n",
        "\n",
        "conv_window.plot('Close',model = conv_model)\n"
      ],
      "metadata": {
        "id": "GnKw-2xQTkXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVOLUTION MODEL ON WIDER WINDOW (30 days)\n",
        "LABEL_WIDTH = 30\n",
        "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
        "wide_conv_window = WindowGenerator(\n",
        "    train_df = train_df, val_df = val_df, test_df = test_df,\n",
        "    input_width=INPUT_WIDTH,\n",
        "    label_width=LABEL_WIDTH,\n",
        "    shift=1,\n",
        "    label_columns=['Close'])\n",
        "\n",
        "print(\"Wide conv window\")\n",
        "print('Input shape:', wide_conv_window.example[0].shape)\n",
        "print('Labels shape:', wide_conv_window.example[1].shape)\n",
        "print('Output shape:', conv_model(wide_conv_window.example[0]).shape)\n",
        "\n",
        "wide_conv_window.plot('Close',model=conv_model)\n"
      ],
      "metadata": {
        "id": "bZtKZKxSTkU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BASIC LSTM MODEL\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "print('Input shape:', wide_window.example[0].shape)\n",
        "print('Output shape:', lstm_model(wide_window.example[0]).shape)\n",
        "\n",
        "history = compile_and_fit(lstm_model, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
        "performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)\n",
        "\n",
        "wide_window.plot('Close', model = lstm_model)\n"
      ],
      "metadata": {
        "id": "iZmx0lr5TkSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual LSTM Model Using the Residual Wrapper\n",
        "residual_lstm = ResidualWrapper(\n",
        "    tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.Dense(\n",
        "        num_features,\n",
        "        # The predicted deltas should start small.\n",
        "        # Therefore, initialize the output layer with zeros.\n",
        "        kernel_initializer=tf.initializers.zeros())\n",
        "]))\n",
        "\n",
        "history = compile_and_fit(residual_lstm, wide_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
        "performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
        "\n",
        "wide_window.plot('Close', model = residual_lstm)"
      ],
      "metadata": {
        "id": "xagve3PYWSCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "x = np.arange(len(performance))\n",
        "width = 0.3\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in performance.values()]\n",
        "\n",
        "plt.ylabel('mean_absolute_error [Close Price]')\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=performance.keys(), rotation=45)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for name, value in performance.items():\n",
        "  print(f'{name:12s}: {value[1]:0.4f}')"
      ],
      "metadata": {
        "id": "nD3Iw283WR_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_STEPS = 30\n",
        "multi_window = WindowGenerator(input_width=30,\n",
        "                               train_df = train_df, val_df = val_df, test_df = test_df,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS,\n",
        "                               label_columns=['Close'])\n",
        "\n",
        "multi_window.plot('Close')\n"
      ],
      "metadata": {
        "id": "4TjWhnj4WR6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_baseline = MultiStepLastBaseline()\n",
        "last_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                      metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot('Close',model = last_baseline)\n"
      ],
      "metadata": {
        "id": "KNPMG7ZiWR33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repeat_baseline = RepeatBaseline()\n",
        "repeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                        metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\n",
        "multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot('Close',model = repeat_baseline)"
      ],
      "metadata": {
        "id": "ZrwlGcbXjVEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MULTI STEP LINEAR MODEL 30 DAYS FORWARD\n",
        "multi_linear_model = tf.keras.Sequential([\n",
        "    # Take the last time-step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_linear_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\n",
        "multi_performance['Linear'] = multi_linear_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot('Close',model = multi_linear_model)"
      ],
      "metadata": {
        "id": "53PyUN9djdTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MULTI STEP LINEAR (DENSE LAYER) MODEL 30 DAYS FORWARD\n",
        "multi_dense_model = tf.keras.Sequential([\n",
        "    # Take the last time step.\n",
        "    # Shape [batch, time, features] => [batch, 1, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
        "    # Shape => [batch, 1, dense_units]\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Shape => [batch, out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_dense_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "multi_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\n",
        "multi_performance['Dense'] = multi_dense_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot('Close',model = multi_dense_model)"
      ],
      "metadata": {
        "id": "LolEKBu8juHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVOLUTION MODEL FOR MULTI STEP WINDOW (30 DAYS AHEAD)\n",
        "CONV_WIDTH = 3\n",
        "multi_conv_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
        "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "    # Shape => [batch, 1, conv_units]\n",
        "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
        "    # Shape => [batch, 1,  out_steps*features]\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features]\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_conv_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
        "multi_performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot('Close',model = multi_conv_model)\n"
      ],
      "metadata": {
        "id": "d3BoU54blkkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM MODEL FOR MULTI STEP WINDOW (30 DAYS AHEAD)\n",
        "multi_lstm_model = tf.keras.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, lstm_units].\n",
        "    # Adding more `lstm_units` just overfits more quickly.\n",
        "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "\n",
        "    # Shape => [batch, out_steps*features].\n",
        "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
        "                          kernel_initializer=tf.initializers.zeros()),\n",
        "    # Shape => [batch, out_steps, features].\n",
        "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history = compile_and_fit(multi_lstm_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
        "multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot('Close',model = multi_lstm_model)"
      ],
      "metadata": {
        "id": "kM4sYwe0mNo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedBack(tf.keras.Model):\n",
        "  def __init__(self, units, out_steps):\n",
        "    super().__init__()\n",
        "    self.out_steps = out_steps\n",
        "    self.units = units\n",
        "    self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
        "    # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
        "    self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(num_features)\n",
        "  def warmup(self, inputs):\n",
        "    # inputs.shape => (batch, time, features)\n",
        "    # x.shape => (batch, lstm_units)\n",
        "    x, *state = self.lstm_rnn(inputs)\n",
        "\n",
        "    # predictions.shape => (batch, features)\n",
        "    prediction = self.dense(x)\n",
        "    return prediction, state\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    # Use a TensorArray to capture dynamically unrolled outputs.\n",
        "    predictions = []\n",
        "    # Initialize the LSTM state.\n",
        "    prediction, state = self.warmup(inputs)\n",
        "\n",
        "    # Insert the first prediction.\n",
        "    predictions.append(prediction)\n",
        "\n",
        "    # Run the rest of the prediction steps.\n",
        "    for n in range(1, self.out_steps):\n",
        "      # Use the last prediction as input.\n",
        "      x = prediction\n",
        "      # Execute one lstm step.\n",
        "      x, state = self.lstm_cell(x, states=state,\n",
        "                                training=training)\n",
        "      # Convert the lstm output to a prediction.\n",
        "      prediction = self.dense(x)\n",
        "      # Add the prediction to the output.\n",
        "      predictions.append(prediction)\n",
        "\n",
        "    # predictions.shape => (time, batch, features)\n",
        "    predictions = tf.stack(predictions)\n",
        "    # predictions.shape => (batch, time, features)\n",
        "    predictions = tf.transpose(predictions, [1, 0, 2])\n",
        "    return predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "h0jh5potnlnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)\n",
        "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
        "prediction.shape\n",
        "\n",
        "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)\n",
        "\n",
        "history = compile_and_fit(feedback_model, multi_window)\n",
        "\n",
        "IPython.display.clear_output()\n",
        "\n",
        "multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n",
        "multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n",
        "multi_window.plot('Close',model = feedback_model)\n"
      ],
      "metadata": {
        "id": "hoAkWngGomGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(len(multi_performance))\n",
        "width = 0.3\n",
        "\n",
        "metric_name = 'mean_absolute_error'\n",
        "metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
        "val_mae = [v[metric_index] for v in multi_val_performance.values()]\n",
        "test_mae = [v[metric_index] for v in multi_performance.values()]\n",
        "\n",
        "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
        "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
        "plt.xticks(ticks=x, labels=multi_performance.keys(),\n",
        "           rotation=45)\n",
        "plt.ylabel(f'MAE (average over all times and outputs)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for name, value in multi_performance.items():\n",
        "  print(f'{name:8s}: {value[1]:0.4f}')"
      ],
      "metadata": {
        "id": "CvcG4wCFo4Q_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}